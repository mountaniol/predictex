# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Ollama –¥–ª—è QnA Evaluator

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Ollama –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö AI –º–æ–¥–µ–ª–µ–π –≤–º–µ—Å—Ç–æ OpenAI.

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞-ollama)
2. [–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π](#–∑–∞–≥—Ä—É–∑–∫–∞-–º–æ–¥–µ–ª–µ–π)
3. [–ù–∞—Å—Ç—Ä–æ–π–∫–∞ QnA Evaluator](#–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-qna-evaluator)
4. [–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏](#–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ-–º–µ–∂–¥—É-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏)
5. [–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏](#—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ-–º–æ–¥–µ–ª–∏)
6. [–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫](#—É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ-–Ω–µ–ø–æ–ª–∞–¥–æ–∫)

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama

### Linux / macOS
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Windows
–°–∫–∞—á–∞–π—Ç–µ —É—Å—Ç–∞–Ω–æ–≤—â–∏–∫ —Å [–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞ Ollama](https://ollama.com/download/windows)

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
```bash
ollama --version
```

## üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π

### –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –Ω–∞—á–∞–ª–∞)
```bash
# Llama 3.1 8B - –æ—Ç–ª–∏—á–Ω—ã–π –±–∞–ª–∞–Ω—Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
ollama pull llama3.1:8b
```

### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
```bash
# –î–ª—è –±–æ–ª–µ–µ –º–æ—â–Ω—ã—Ö —Å–∏—Å—Ç–µ–º (—Ç—Ä–µ–±—É–µ—Ç ~26GB RAM)
ollama pull llama3.1:70b

# –õ–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–ª–∞–±—ã—Ö —Å–∏—Å—Ç–µ–º
ollama pull phi3:mini

# –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞
ollama pull codellama:13b

# –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å
ollama pull saiga:7b
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
```bash
ollama list
```

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ QnA Evaluator

### 1. –û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
```bash
nano public/app.config.json
```

### 2. –ò–∑–º–µ–Ω–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –Ω–∞ Ollama
```json
{
  "Backend": {
    "ai_provider": "ollama",  // –ò–∑–º–µ–Ω–∏—Ç—å —Å "openai" –Ω–∞ "ollama"
    "ollama": {
      "base_url": "http://localhost:11434",
      "model": "llama3.1:8b",  // –£–∫–∞–∂–∏—Ç–µ –≤–∞—à—É –º–æ–¥–µ–ª—å
      "default_temperature": 0.3,
      "default_max_tokens": 1024,
      "stream": true
    },
    ...
  }
}
```

### 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama —Å–µ—Ä–≤–µ—Ä
```bash
# Ollama –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∫ —Å–µ—Ä–≤–∏—Å –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Ä—É—á–Ω—É—é:
ollama serve
```

### 4. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ backend
```bash
./run-backend.sh
```

## üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ OpenAI
```json
{
  "Backend": {
    "ai_provider": "openai",
    ...
  }
}
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Ollama
```json
{
  "Backend": {
    "ai_provider": "ollama",
    ...
  }
}
```

## üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### –î–ª—è –æ–±—â–∏—Ö –∑–∞–¥–∞—á
- **llama3.1:8b** - –õ—É—á—à–∏–π –≤—ã–±–æ—Ä –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á
- **mistral:7b** - –ë—ã—Å—Ç—Ä–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞

### –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–∏–∑–Ω–µ—Å–∞
- **llama3.1:70b** - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (—Ç—Ä–µ–±—É–µ—Ç –º–æ—â–Ω–æ–µ –∂–µ–ª–µ–∑–æ)
- **mixtral:8x7b** - –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π

### –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º
- **codellama:13b** - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ –∫–æ–¥–µ
- **deepseek-coder:6.7b** - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –¥–ª—è –∫–æ–¥–∞

### –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
- **saiga:7b** - –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
- **openchat:7b** - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —è–∑—ã–∫–æ–≤

## üõ†Ô∏è –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º–∞: "Model not found"
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
ollama list

# –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å
ollama pull –∏–º—è_–º–æ–¥–µ–ª–∏
```

### –ü—Ä–æ–±–ª–µ–º–∞: "Connection refused"
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –∑–∞–ø—É—â–µ–Ω –ª–∏ Ollama
curl http://localhost:11434/api/tags

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama –≤—Ä—É—á–Ω—É—é
ollama serve
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, phi3:mini)
2. –£–º–µ–Ω—å—à–∏—Ç–µ max_tokens –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU:
   ```bash
   # –î–ª—è NVIDIA
   nvidia-smi
   
   # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –≤ Ollama
   ollama run llama3.1:8b --verbose
   ```

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
1. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ temperature (0.1-0.5 –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, 0.7-1.0 –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏)
3. –£–≤–µ–ª–∏—á—å—Ç–µ max_tokens –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

| –ú–æ–¥–µ–ª—å | RAM | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|--------|-----|----------|----------|--------------|
| phi3:mini | 2GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | –î–ª—è —Å–ª–∞–±—ã—Ö –ü–ö |
| llama3.1:8b | 8GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä |
| mixtral:8x7b | 26GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –î–ª—è –º–æ—â–Ω—ã—Ö –ü–ö |
| llama3.1:70b | 40GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ |

## üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ Ollama
```bash
# Linux/macOS
journalctl -u ollama -f

# –ò–ª–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤ –≤ –∫–æ–Ω—Å–æ–ª–∏
ollama serve
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
```bash
# CPU –∏ RAM
htop

# GPU (NVIDIA)
nvidia-smi -l 1
```

## üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

### 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU (NVIDIA)
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA
ollama run llama3.1:8b --verbose
```

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –ø–∞–º—è—Ç–∏
```bash
# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
export OLLAMA_MAX_LOADED_MODELS=1
export OLLAMA_NUM_PARALLEL=2
```

### 3. –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
```bash
# –î–µ—Ä–∂–∞—Ç—å –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç–∏
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.1:8b",
  "keep_alive": -1
}'
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Ollama](https://github.com/ollama/ollama)
- [–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π](https://ollama.com/library)
- [Ollama API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://github.com/ollama/ollama/blob/main/docs/api.md)

---

üí° **–°–æ–≤–µ—Ç**: –ù–∞—á–Ω–∏—Ç–µ —Å –º–æ–¥–µ–ª–∏ `llama3.1:8b` - –æ–Ω–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á.